{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서 로드 완료\n",
            "문서 길이: 15431 문자\n",
            "첫 100자: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "| --- | --- |\n",
            "| 든든급식 개편사항 안내(10\n"
          ]
        }
      ],
      "source": [
        "# 문서 로드\n",
        "with open(\"9f9e37a6-55f4-43c4-8285-b4b976f5dd4b.md\", \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "print(\"문서 로드 완료\")\n",
        "print(f\"문서 길이: {len(content)} 문자\")\n",
        "print(f\"첫 100자: {content[:100]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "라이브러리 로드 완료\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치 및 로드\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from elasticsearch import Elasticsearch\n",
        "import json\n",
        "\n",
        "print(\"라이브러리 로드 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서가 23개의 chunk로 분할되었습니다.\n"
          ]
        }
      ],
      "source": [
        "# 텍스트 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=10,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "docs = text_splitter.create_documents([content])\n",
        "print(f\"문서가 {len(docs)}개의 chunk로 분할되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Elasticsearch 연결 성공!\n",
            "✅ Nori 플러그인 설치 확인됨!\n"
          ]
        }
      ],
      "source": [
        "# Elasticsearch 연결 (Nori 플러그인 설치됨)\n",
        "es = Elasticsearch(\n",
        "    hosts=[\"http://localhost:9200\"],\n",
        "    verify_certs=False,\n",
        "    ssl_show_warn=False\n",
        ")\n",
        "\n",
        "# 연결 및 플러그인 확인\n",
        "if es.ping():\n",
        "    print(\"✅ Elasticsearch 연결 성공!\")\n",
        "    \n",
        "    # 플러그인 확인\n",
        "    plugins = es.cat.plugins(format=\"json\")\n",
        "    nori_installed = any(plugin.get('component') == 'analysis-nori' for plugin in plugins)\n",
        "    \n",
        "    if nori_installed:\n",
        "        print(\"✅ Nori 플러그인 설치 확인됨!\")\n",
        "    else:\n",
        "        print(\"❌ Nori 플러그인이 설치되지 않았습니다.\")\n",
        "else:\n",
        "    print(\"❌ Elasticsearch 연결 실패\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 Nori 분석기 테스트 시작...\n",
            "기존 테스트 인덱스 삭제\n",
            "✅ 기본 Nori 인덱스 생성 성공!\n",
            "✅ 분석 테스트 성공: '장점' → ['장점']\n"
          ]
        }
      ],
      "source": [
        "# 먼저 간단한 Nori 테스트부터 시작\n",
        "print(\"🧪 Nori 분석기 테스트 시작...\")\n",
        "\n",
        "# 가장 기본적인 Nori 설정으로 테스트\n",
        "simple_nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"simple_korean\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"analyzer\": \"simple_korean\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 테스트 인덱스 생성\n",
        "test_index = \"nori_test\"\n",
        "\n",
        "if es.indices.exists(index=test_index):\n",
        "    es.indices.delete(index=test_index)\n",
        "    print(\"기존 테스트 인덱스 삭제\")\n",
        "\n",
        "try:\n",
        "    es.indices.create(index=test_index, body=simple_nori_mapping)\n",
        "    print(\"✅ 기본 Nori 인덱스 생성 성공!\")\n",
        "    \n",
        "    # 간단한 텍스트 분석 테스트\n",
        "    test_text = \"장점\"\n",
        "    response = es.indices.analyze(\n",
        "        index=test_index,\n",
        "        body={\"analyzer\": \"simple_korean\", \"text\": test_text}\n",
        "    )\n",
        "    tokens = [token['token'] for token in response['tokens']]\n",
        "    print(f\"✅ 분석 테스트 성공: '{test_text}' → {tokens}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ 오류 발생: {e}\")\n",
        "    print(\"기본 Standard 분석기로 대체합니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📁 'bm25_standard' 인덱스에 문서 인덱싱 중...\n",
            "✅ 23개 chunk 인덱싱 완료\n",
            "\n",
            "📁 'bm25_nori' 인덱스에 문서 인덱싱 중...\n",
            "✅ 23개 chunk 인덱싱 완료\n",
            "\n",
            "📁 'bm25_ngram' 인덱스에 문서 인덱싱 중...\n",
            "✅ 23개 chunk 인덱싱 완료\n",
            "\n",
            "🎉 모든 인덱스 준비 완료!\n"
          ]
        }
      ],
      "source": [
        "# 모든 인덱스에 문서 인덱싱\n",
        "indices_list = [standard_index, nori_index, ngram_index]\n",
        "\n",
        "for index_name in indices_list:\n",
        "    print(f\"\\n📁 '{index_name}' 인덱스에 문서 인덱싱 중...\")\n",
        "    \n",
        "    for i, doc in enumerate(docs):\n",
        "        document = {\n",
        "            \"content\": doc.page_content,\n",
        "            \"chunk_id\": i\n",
        "        }\n",
        "        es.index(index=index_name, id=i, body=document)\n",
        "    \n",
        "    es.indices.refresh(index=index_name)\n",
        "    print(f\"✅ {len(docs)}개 chunk 인덱싱 완료\")\n",
        "\n",
        "print(\"\\n🎉 모든 인덱스 준비 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검색 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "# 검색 함수 정의\n",
        "def search_with_analyzer(query, index_name, top_k=3):\n",
        "    \"\"\"지정된 인덱스에서 BM25 검색 수행\"\"\"\n",
        "    search_body = {\n",
        "        \"size\": top_k,\n",
        "        \"query\": {\n",
        "            \"match\": {\n",
        "                \"content\": {\n",
        "                    \"query\": query,\n",
        "                    \"operator\": \"or\"\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"_source\": [\"content\", \"chunk_id\"]\n",
        "    }\n",
        "    \n",
        "    response = es.search(index=index_name, body=search_body)\n",
        "    results = []\n",
        "    \n",
        "    for hit in response['hits']['hits']:\n",
        "        results.append({\n",
        "            'chunk_id': hit['_source']['chunk_id'],\n",
        "            'score': hit['_score'],\n",
        "            'content': hit['_source']['content']\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"검색 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏆 한글 BM25 성능 비교: Standard vs Nori vs N-gram\n",
            "================================================================================\n",
            "\n",
            "🔍 검색어: '서울든든급식'\n",
            "============================================================\n",
            "1️⃣ Standard 분석기:\n",
            "   [1] Chunk 7 - 점수: 2.8021\n",
            "       내용: 11월 20일(수)부터 '24년 12월분 식재료 주문이 가능합니다.\n",
            "\n",
            "성동구 어린이집 대상 신규 회원가입 안내 >\n",
            "\n",
            "회원가입 ...\n",
            "   [2] Chunk 0 - 점수: 2.6964\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "\n",
            "2️⃣ Nori 분석기 (한글 형태소 분석):\n",
            "   [1] Chunk 0 - 점수: 5.0503\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "   [2] Chunk 7 - 점수: 4.7894\n",
            "       내용: 11월 20일(수)부터 '24년 12월분 식재료 주문이 가능합니다.\n",
            "\n",
            "성동구 어린이집 대상 신규 회원가입 안내 >\n",
            "\n",
            "회원가입 ...\n",
            "\n",
            "3️⃣ N-gram 분석기 (2-3글자 단위):\n",
            "   [1] Chunk 0 - 점수: 0.9590\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "   [2] Chunk 7 - 점수: 0.9590\n",
            "       내용: 11월 20일(수)부터 '24년 12월분 식재료 주문이 가능합니다.\n",
            "\n",
            "성동구 어린이집 대상 신규 회원가입 안내 >\n",
            "\n",
            "회원가입 ...\n",
            "\n",
            "============================================================\n",
            "\n",
            "🔍 검색어: '식재료 주문'\n",
            "============================================================\n",
            "1️⃣ Standard 분석기:\n",
            "   [1] Chunk 8 - 점수: 2.7022\n",
            "       내용: 5\n",
            "\n",
            "해당 식재료를 담을 수 있는\n",
            "날짜 표출\n",
            "\n",
            "* 오늘(주문일) 기준\n",
            "\n",
            "# 7일 뒤부터 주문 가능ex) 오늘이 수요일이라면,\n",
            "...\n",
            "   [2] Chunk 7 - 점수: 2.2662\n",
            "       내용: 11월 20일(수)부터 '24년 12월분 식재료 주문이 가능합니다.\n",
            "\n",
            "성동구 어린이집 대상 신규 회원가입 안내 >\n",
            "\n",
            "회원가입 ...\n",
            "\n",
            "2️⃣ Nori 분석기 (한글 형태소 분석):\n",
            "   [1] Chunk 8 - 점수: 1.6781\n",
            "       내용: 5\n",
            "\n",
            "해당 식재료를 담을 수 있는\n",
            "날짜 표출\n",
            "\n",
            "* 오늘(주문일) 기준\n",
            "\n",
            "# 7일 뒤부터 주문 가능ex) 오늘이 수요일이라면,\n",
            "...\n",
            "   [2] Chunk 13 - 점수: 1.6150\n",
            "       내용: # 입력을# 클릭# 필요 없을안해도 됨\n",
            "\n",
            "# 경우)7일 전)\n",
            "\n",
            "처리\n",
            "\n",
            "# 4. 메인화면 장바구니 (3/3)# Descripti...\n",
            "\n",
            "3️⃣ N-gram 분석기 (2-3글자 단위):\n",
            "   [1] Chunk 8 - 점수: 0.3460\n",
            "       내용: 5\n",
            "\n",
            "해당 식재료를 담을 수 있는\n",
            "날짜 표출\n",
            "\n",
            "* 오늘(주문일) 기준\n",
            "\n",
            "# 7일 뒤부터 주문 가능ex) 오늘이 수요일이라면,\n",
            "...\n",
            "   [2] Chunk 13 - 점수: 0.3456\n",
            "       내용: # 입력을# 클릭# 필요 없을안해도 됨\n",
            "\n",
            "# 경우)7일 전)\n",
            "\n",
            "처리\n",
            "\n",
            "# 4. 메인화면 장바구니 (3/3)# Descripti...\n",
            "\n",
            "============================================================\n",
            "\n",
            "🔍 검색어: '어린이집'\n",
            "============================================================\n",
            "1️⃣ Standard 분석기:\n",
            "   [1] Chunk 4 - 점수: 1.8941\n",
            "       내용: 1,185개 어린이집 1,459개 어린이집# 2026년# 2025년# 25개 자치구 3,000개 어린이집# SEOUL M! S...\n",
            "   [2] Chunk 3 - 점수: 1.5000\n",
            "       내용: # SEOUL M! SOUL# <은평 송파구> ★# 서울든든급식 이용 일정# 회원가입# 11월 18일까지# → →# 계정승인#...\n",
            "\n",
            "2️⃣ Nori 분석기 (한글 형태소 분석):\n",
            "   [1] Chunk 4 - 점수: 3.1760\n",
            "       내용: 1,185개 어린이집 1,459개 어린이집# 2026년# 2025년# 25개 자치구 3,000개 어린이집# SEOUL M! S...\n",
            "   [2] Chunk 3 - 점수: 2.9030\n",
            "       내용: # SEOUL M! SOUL# <은평 송파구> ★# 서울든든급식 이용 일정# 회원가입# 11월 18일까지# → →# 계정승인#...\n",
            "\n",
            "3️⃣ N-gram 분석기 (2-3글자 단위):\n",
            "   [1] Chunk 3 - 점수: 1.7971\n",
            "       내용: # SEOUL M! SOUL# <은평 송파구> ★# 서울든든급식 이용 일정# 회원가입# 11월 18일까지# → →# 계정승인#...\n",
            "   [2] Chunk 5 - 점수: 1.7918\n",
            "       내용: 설문조사 바!\n",
            "\n",
            "# 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울 든든급식# 어린이집에 건강하고 안전한 식재료 제공을 위해 액(%)# 3,99...\n",
            "\n",
            "============================================================\n",
            "\n",
            "🔍 검색어: '급식'\n",
            "============================================================\n",
            "1️⃣ Standard 분석기:\n",
            "   [1] Chunk 20 - 점수: 2.4442\n",
            "       내용: | No. | 업무처리 기준 | 처리 예시 | 비고 |\n",
            "| --- | --- | --- | --- |\n",
            "| 1 | 급식 인원 및...\n",
            "   [2] Chunk 0 - 점수: 1.9145\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "\n",
            "2️⃣ Nori 분석기 (한글 형태소 분석):\n",
            "   [1] Chunk 0 - 점수: 0.8985\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "   [2] Chunk 16 - 점수: 0.8652\n",
            "       내용: | 우수식재료 지원금 1 급식인원/일수 등록 우수식재료 지원금 > 신청 지원금 배정교부 | 급식인원/일수 등록 우수식재료 지원...\n",
            "\n",
            "3️⃣ N-gram 분석기 (2-3글자 단위):\n",
            "   [1] Chunk 0 - 점수: 0.9461\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "   [2] Chunk 6 - 점수: 0.9401\n",
            "       내용: # 4. 식재료 주문 방법# 1 식재료주문 서울든든급식 웹쇼핑몰 이용# · 발주기한 납품일 기준 7일 전까지- x (은평·송파...\n",
            "\n",
            "============================================================\n",
            "\n",
            "🔍 검색어: '든든'\n",
            "============================================================\n",
            "1️⃣ Standard 분석기:\n",
            "   검색 결과 없음\n",
            "\n",
            "2️⃣ Nori 분석기 (한글 형태소 분석):\n",
            "   [1] Chunk 0 - 점수: 2.2943\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "   [2] Chunk 7 - 점수: 2.2044\n",
            "       내용: 11월 20일(수)부터 '24년 12월분 식재료 주문이 가능합니다.\n",
            "\n",
            "성동구 어린이집 대상 신규 회원가입 안내 >\n",
            "\n",
            "회원가입 ...\n",
            "\n",
            "3️⃣ N-gram 분석기 (2-3글자 단위):\n",
            "   [1] Chunk 0 - 점수: 2.5011\n",
            "       내용: # 든든히 먹고\n",
            "튼튼히 크는\n",
            "서울든든급식# SE♡UL M! SOUL# 서울특별시# < 진행 순서 >| 내 용 | 진 행 |\n",
            "|...\n",
            "   [2] Chunk 7 - 점수: 2.4908\n",
            "       내용: 11월 20일(수)부터 '24년 12월분 식재료 주문이 가능합니다.\n",
            "\n",
            "성동구 어린이집 대상 신규 회원가입 안내 >\n",
            "\n",
            "회원가입 ...\n",
            "\n",
            "============================================================\n",
            "\n",
            "🔍 검색어: '회원가입'\n",
            "============================================================\n",
            "1️⃣ Standard 분석기:\n",
            "   [1] Chunk 3 - 점수: 2.6460\n",
            "       내용: # SEOUL M! SOUL# <은평 송파구> ★# 서울든든급식 이용 일정# 회원가입# 11월 18일까지# → →# 계정승인#...\n",
            "   [2] Chunk 6 - 점수: 2.6460\n",
            "       내용: # 4. 식재료 주문 방법# 1 식재료주문 서울든든급식 웹쇼핑몰 이용# · 발주기한 납품일 기준 7일 전까지- x (은평·송파...\n",
            "\n",
            "2️⃣ Nori 분석기 (한글 형태소 분석):\n",
            "   [1] Chunk 3 - 점수: 4.9071\n",
            "       내용: # SEOUL M! SOUL# <은평 송파구> ★# 서울든든급식 이용 일정# 회원가입# 11월 18일까지# → →# 계정승인#...\n",
            "   [2] Chunk 6 - 점수: 4.8008\n",
            "       내용: # 4. 식재료 주문 방법# 1 식재료주문 서울든든급식 웹쇼핑몰 이용# · 발주기한 납품일 기준 7일 전까지- x (은평·송파...\n",
            "\n",
            "3️⃣ N-gram 분석기 (2-3글자 단위):\n",
            "   [1] Chunk 3 - 점수: 3.1933\n",
            "       내용: # SEOUL M! SOUL# <은평 송파구> ★# 서울든든급식 이용 일정# 회원가입# 11월 18일까지# → →# 계정승인#...\n",
            "   [2] Chunk 6 - 점수: 3.1933\n",
            "       내용: # 4. 식재료 주문 방법# 1 식재료주문 서울든든급식 웹쇼핑몰 이용# · 발주기한 납품일 기준 7일 전까지- x (은평·송파...\n",
            "\n",
            "============================================================\n",
            "\n",
            "🔍 검색어: '장점점'\n",
            "============================================================\n",
            "1️⃣ Standard 분석기:\n",
            "   검색 결과 없음\n",
            "\n",
            "2️⃣ Nori 분석기 (한글 형태소 분석):\n",
            "   [1] Chunk 2 - 점수: 5.1660\n",
            "       내용: # SEOUL M.SOUL# 서울든든급식의 장점은?# 서울시가 운영하는 공적 조달 체계!\n",
            "1 엄격한 안전성 및 품질 검사\n",
            "2 ...\n",
            "   [2] Chunk 11 - 점수: 2.1342\n",
            "       내용: | 건포도/미웰 건포도/수입산/0.5kg 냉장보관 일반 0.5 kg : 3890원 소수점 발주 불가능한 상품입니다. <tabl...\n",
            "\n",
            "3️⃣ N-gram 분석기 (2-3글자 단위):\n",
            "   [1] Chunk 2 - 점수: 4.6896\n",
            "       내용: # SEOUL M.SOUL# 서울든든급식의 장점은?# 서울시가 운영하는 공적 조달 체계!\n",
            "1 엄격한 안전성 및 품질 검사\n",
            "2 ...\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 🏆 3가지 분석기 성능 비교 테스트\n",
        "print(\"🏆 한글 BM25 성능 비교: Standard vs Nori vs N-gram\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "test_queries = [\n",
        "    \"서울든든급식\",\n",
        "    \"식재료 주문\", \n",
        "    \"어린이집\",\n",
        "    \"급식\",\n",
        "    \"든든\",\n",
        "    \"회원가입\",\n",
        "    \"장점점\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n🔍 검색어: '{query}'\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 1. Standard 분석기\n",
        "    print(\"1️⃣ Standard 분석기:\")\n",
        "    standard_results = search_with_analyzer(query, standard_index, top_k=2)\n",
        "    if standard_results:\n",
        "        for i, result in enumerate(standard_results, 1):\n",
        "            print(f\"   [{i}] Chunk {result['chunk_id']} - 점수: {result['score']:.4f}\")\n",
        "            print(f\"       내용: {result['content'][:70]}...\")\n",
        "    else:\n",
        "        print(\"   검색 결과 없음\")\n",
        "    \n",
        "    # 2. Nori 분석기 (한글 형태소 분석)\n",
        "    print(\"\\n2️⃣ Nori 분석기 (한글 형태소 분석):\")\n",
        "    nori_results = search_with_analyzer(query, nori_index, top_k=2)\n",
        "    if nori_results:\n",
        "        for i, result in enumerate(nori_results, 1):\n",
        "            print(f\"   [{i}] Chunk {result['chunk_id']} - 점수: {result['score']:.4f}\")\n",
        "            print(f\"       내용: {result['content'][:70]}...\")\n",
        "    else:\n",
        "        print(\"   검색 결과 없음\")\n",
        "    \n",
        "    # 3. N-gram 분석기\n",
        "    print(\"\\n3️⃣ N-gram 분석기 (2-3글자 단위):\")\n",
        "    ngram_results = search_with_analyzer(query, ngram_index, top_k=2)\n",
        "    if ngram_results:\n",
        "        for i, result in enumerate(ngram_results, 1):\n",
        "            print(f\"   [{i}] Chunk {result['chunk_id']} - 점수: {result['score']:.4f}\")\n",
        "            print(f\"       내용: {result['content'][:70]}...\")\n",
        "    else:\n",
        "        print(\"   검색 결과 없음\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 토크나이저 분석 결과 비교\n",
            "============================================================\n",
            "\n",
            "📝 분석 텍스트: '서울든든급식'\n",
            "----------------------------------------\n",
            "🔹 Standard: ['서울든든급식']\n",
            "🔹 Nori:     ['서울', '든든', '급식']\n",
            "🔹 N-gram:   ['서울', '서울든', '울든', '울든든', '든든', '든든급', '든급', '든급식']...\n",
            "💡 토큰 개수 - Standard: 1, Nori: 3, N-gram: 9\n",
            "----------------------------------------\n",
            "\n",
            "📝 분석 텍스트: '식재료 주문 방법'\n",
            "----------------------------------------\n",
            "🔹 Standard: ['식재료', '주문', '방법']\n",
            "🔹 Nori:     ['식', '재료', '주문', '방법']\n",
            "🔹 N-gram:   ['식재', '식재료', '재료', '재료 ', '료 ', '료 주', ' 주', ' 주문']...\n",
            "💡 토큰 개수 - Standard: 3, Nori: 4, N-gram: 15\n",
            "----------------------------------------\n",
            "\n",
            "📝 분석 텍스트: '어린이집 대상 신규 회원가입'\n",
            "----------------------------------------\n",
            "🔹 Standard: ['어린이집', '대상', '신규', '회원가입']\n",
            "🔹 Nori:     ['어린이', '집', '대상', '신규', '회원', '가입']\n",
            "🔹 N-gram:   ['어린', '어린이', '린이', '린이집', '이집', '이집 ', '집 ', '집 대']...\n",
            "💡 토큰 개수 - Standard: 4, Nori: 6, N-gram: 27\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 토크나이저 분석 결과 비교\n",
        "print(\"\\n🔍 토크나이저 분석 결과 비교\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def analyze_text(text, analyzer_name, index_name):\n",
        "    \"\"\"텍스트 분석 결과 반환\"\"\"\n",
        "    try:\n",
        "        response = es.indices.analyze(\n",
        "            index=index_name,\n",
        "            body={\"analyzer\": analyzer_name, \"text\": text}\n",
        "        )\n",
        "        return [token['token'] for token in response['tokens']]\n",
        "    except Exception as e:\n",
        "        print(f\"분석 실패: {e}\")\n",
        "        return []\n",
        "\n",
        "sample_texts = [\n",
        "    \"서울든든급식\",\n",
        "    \"식재료 주문 방법\",\n",
        "    \"어린이집 대상 신규 회원가입\"\n",
        "]\n",
        "\n",
        "for text in sample_texts:\n",
        "    print(f\"\\n📝 분석 텍스트: '{text}'\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Standard 분석\n",
        "    standard_tokens = analyze_text(text, \"standard\", standard_index)\n",
        "    print(f\"🔹 Standard: {standard_tokens}\")\n",
        "    \n",
        "    # Nori 분석\n",
        "    nori_tokens = analyze_text(text, \"korean_analyzer\", nori_index)\n",
        "    print(f\"🔹 Nori:     {nori_tokens}\")\n",
        "    \n",
        "    # N-gram 분석 (일부만 표시)\n",
        "    ngram_tokens = analyze_text(text, \"ngram_analyzer\", ngram_index)\n",
        "    print(f\"🔹 N-gram:   {ngram_tokens[:8]}{'...' if len(ngram_tokens) > 8 else ''}\")\n",
        "    \n",
        "    print(f\"💡 토큰 개수 - Standard: {len(standard_tokens)}, Nori: {len(nori_tokens)}, N-gram: {len(ngram_tokens)}\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "f-string expression part cannot include a backslash (983037729.py, line 9)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"문서 제목: {new_content.split('\\\\n')[0][:50]}...\")\u001b[39m\n                                                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m f-string expression part cannot include a backslash\n"
          ]
        }
      ],
      "source": [
        "# 📄 새로운 문서 추가: AX브릿지위원회 소개자료\n",
        "print(\"📄 새로운 문서 로드 중...\")\n",
        "\n",
        "# 새로운 문서 로드\n",
        "with open(\"ceca9bf3-6183-40bc-ad64-52911b2015b3.md\", \"r\", encoding=\"utf-8\") as file:\n",
        "    new_content = file.read()\n",
        "\n",
        "print(f\"✅ 새 문서 로드 완료: {len(new_content)} 문자\")\n",
        "print(f\"문서 제목: {new_content.split('\\\\n')[0][:50]}...\")\n",
        "\n",
        "# 새 문서도 동일한 방식으로 분할\n",
        "new_docs = text_splitter.create_documents([new_content])\n",
        "print(f\"✅ 새 문서가 {len(new_docs)}개의 chunk로 분할되었습니다.\")\n",
        "\n",
        "# 기존 chunk 개수 확인\n",
        "print(f\"기존 문서 chunk 개수: {len(docs)}\")\n",
        "print(f\"새 문서 chunk 개수: {len(new_docs)}\")\n",
        "print(f\"총 chunk 개수: {len(docs) + len(new_docs)}\")\n",
        "\n",
        "# 전체 문서 리스트 결합\n",
        "all_docs = docs + new_docs\n",
        "print(f\"\\\\n🎯 총 {len(all_docs)}개의 chunk로 확장되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔄 기존 인덱스에 새로운 문서 추가\n",
        "print(\"🔄 기존 인덱스에 새로운 문서 추가 중...\")\n",
        "\n",
        "# 기존 chunk 개수를 시작 ID로 사용\n",
        "start_id = len(docs)\n",
        "\n",
        "# 모든 인덱스에 새로운 문서 추가\n",
        "for index_name in indices_list:\n",
        "    print(f\"\\\\n📁 '{index_name}' 인덱스에 새 문서 추가 중...\")\n",
        "    \n",
        "    # 새로운 chunk들을 기존 인덱스에 추가\n",
        "    for i, doc in enumerate(new_docs):\n",
        "        document = {\n",
        "            \"content\": doc.page_content,\n",
        "            \"chunk_id\": start_id + i,  # 기존 ID에 이어서 번호 부여\n",
        "            \"source\": \"AX브릿지위원회\"  # 출처 구분을 위한 필드 추가\n",
        "        }\n",
        "        es.index(index=index_name, id=start_id + i, body=document)\n",
        "    \n",
        "    # 인덱스 새로고침\n",
        "    es.indices.refresh(index=index_name)\n",
        "    print(f\"✅ {len(new_docs)}개 새 chunk 추가 완료\")\n",
        "\n",
        "print(f\"\\\\n🎉 모든 인덱스 업데이트 완료!\")\n",
        "print(f\"📊 총 문서 수: {len(all_docs)}개 chunk\")\n",
        "print(f\"   - 서울든든급식: {len(docs)}개\")\n",
        "print(f\"   - AX브릿지위원회: {len(new_docs)}개\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기존 인덱스 'bm25_standard' 삭제\n",
            "✅ 인덱스 'bm25_standard' 생성 완료\n",
            "기존 인덱스 'bm25_nori' 삭제\n",
            "✅ 인덱스 'bm25_nori' 생성 완료\n",
            "기존 인덱스 'bm25_ngram' 삭제\n",
            "✅ 인덱스 'bm25_ngram' 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 3가지 인덱스 생성: Standard, Nori, N-gram\n",
        "\n",
        "# 1. Standard 분석기 인덱스\n",
        "standard_index = \"bm25_standard\"\n",
        "standard_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"bm25_similarity\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"bm25_similarity\", \"analyzer\": \"standard\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Nori 분석기 인덱스 (간단하고 안전한 설정)\n",
        "nori_index = \"bm25_nori\"\n",
        "nori_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"korean_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"korean_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"nori_tokenizer\",\n",
        "                    \"filter\": [\"lowercase\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"korean_bm25\", \"analyzer\": \"korean_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. N-gram 분석기 인덱스\n",
        "ngram_index = \"bm25_ngram\"\n",
        "ngram_mapping = {\n",
        "    \"settings\": {\n",
        "        \"index\": {\n",
        "            \"similarity\": {\n",
        "                \"ngram_bm25\": {\"type\": \"BM25\", \"k1\": 1.2, \"b\": 0.75}\n",
        "            }\n",
        "        },\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"ngram_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"keyword\",\n",
        "                    \"filter\": [\"lowercase\", \"ngram_filter\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"ngram_filter\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 3}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"text\", \"similarity\": \"ngram_bm25\", \"analyzer\": \"ngram_analyzer\"},\n",
        "            \"chunk_id\": {\"type\": \"integer\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 인덱스 생성\n",
        "indices = [(standard_index, standard_mapping), (nori_index, nori_mapping), (ngram_index, ngram_mapping)]\n",
        "\n",
        "for index_name, mapping in indices:\n",
        "    if es.indices.exists(index=index_name):\n",
        "        es.indices.delete(index=index_name)\n",
        "        print(f\"기존 인덱스 '{index_name}' 삭제\")\n",
        "    \n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "    print(f\"✅ 인덱스 '{index_name}' 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔍 통합 검색 테스트 - 두 문서에서 동시 검색\n",
        "print(\"🔍 통합 검색 테스트 시작!\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 확장된 검색 함수 - 출처 정보 포함\n",
        "def search_with_source(query, index_name, top_k=5):\n",
        "    \"\"\"출처 정보를 포함한 검색 함수\"\"\"\n",
        "    search_body = {\n",
        "        \"size\": top_k,\n",
        "        \"query\": {\n",
        "            \"match\": {\n",
        "                \"content\": {\n",
        "                    \"query\": query,\n",
        "                    \"operator\": \"or\"\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"_source\": [\"content\", \"chunk_id\", \"source\"]\n",
        "    }\n",
        "    \n",
        "    response = es.search(index=index_name, body=search_body)\n",
        "    results = []\n",
        "    \n",
        "    for hit in response['hits']['hits']:\n",
        "        source_info = hit['_source'].get('source', '서울든든급식')  # 기본값은 서울든든급식\n",
        "        results.append({\n",
        "            'chunk_id': hit['_source']['chunk_id'],\n",
        "            'score': hit['_score'],\n",
        "            'content': hit['_source']['content'],\n",
        "            'source': source_info\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# 다양한 검색어로 통합 검색 테스트\n",
        "mixed_queries = [\n",
        "    \"서울든든급식\",      # 첫 번째 문서 관련\n",
        "    \"AX브릿지위원회\",    # 두 번째 문서 관련\n",
        "    \"AI\",               # 두 번째 문서 관련\n",
        "    \"벤처기업\",         # 두 번째 문서 관련\n",
        "    \"메가존클라우드\",   # 두 번째 문서 관련\n",
        "    \"급식\",             # 첫 번째 문서 관련\n",
        "    \"위원회\",           # 두 번째 문서 관련\n",
        "    \"대표이사\"          # 두 번째 문서 관련\n",
        "]\n",
        "\n",
        "print(\"🏆 통합 검색 결과 (Nori 분석기 사용)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for query in mixed_queries:\n",
        "    print(f\"\\\\n🔍 검색어: '{query}'\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Nori 분석기로 검색\n",
        "    results = search_with_source(query, nori_index, top_k=3)\n",
        "    \n",
        "    if results:\n",
        "        for i, result in enumerate(results, 1):\n",
        "            source_emoji = \"🍽️\" if result['source'] == \"서울든든급식\" else \"🚀\"\n",
        "            print(f\"   [{i}] {source_emoji} {result['source']} - Chunk {result['chunk_id']}\")\n",
        "            print(f\"       점수: {result['score']:.4f}\")\n",
        "            print(f\"       내용: {result['content'][:80]}...\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"   검색 결과 없음\")\n",
        "    \n",
        "    print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 문서별 검색 통계 및 분석\n",
        "print(\"\\\\n📊 문서별 검색 통계 분석\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def analyze_search_distribution(query, index_name, top_k=10):\n",
        "    \"\"\"검색 결과의 문서별 분포 분석\"\"\"\n",
        "    results = search_with_source(query, index_name, top_k=top_k)\n",
        "    \n",
        "    # 문서별 개수 계산\n",
        "    source_count = {}\n",
        "    for result in results:\n",
        "        source = result['source']\n",
        "        if source not in source_count:\n",
        "            source_count[source] = 0\n",
        "        source_count[source] += 1\n",
        "    \n",
        "    return results, source_count\n",
        "\n",
        "# 주요 검색어들에 대한 분포 분석\n",
        "analysis_queries = [\"AI\", \"급식\", \"위원회\", \"대표\", \"서울\"]\n",
        "\n",
        "for query in analysis_queries:\n",
        "    print(f\"\\\\n🔍 '{query}' 검색 분포:\")\n",
        "    results, distribution = analyze_search_distribution(query, nori_index, top_k=10)\n",
        "    \n",
        "    total_results = len(results)\n",
        "    if total_results > 0:\n",
        "        print(f\"   총 {total_results}개 결과:\")\n",
        "        for source, count in distribution.items():\n",
        "            percentage = (count / total_results) * 100\n",
        "            emoji = \"🍽️\" if source == \"서울든든급식\" else \"🚀\"\n",
        "            print(f\"   {emoji} {source}: {count}개 ({percentage:.1f}%)\")\n",
        "        \n",
        "        # 상위 3개 결과 표시\n",
        "        print(f\"\\\\n   📋 상위 3개 결과:\")\n",
        "        for i, result in enumerate(results[:3], 1):\n",
        "            source_emoji = \"🍽️\" if result['source'] == \"서울든든급식\" else \"🚀\"\n",
        "            print(f\"   [{i}] {source_emoji} 점수: {result['score']:.3f} - {result['content'][:50]}...\")\n",
        "    else:\n",
        "        print(\"   검색 결과 없음\")\n",
        "    \n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 특정 문서에서만 검색하는 필터 기능\n",
        "print(\"\\n🎯 문서별 필터 검색 기능\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def search_by_source(query, index_name, source_filter=None, top_k=5):\n",
        "    \"\"\"특정 출처 문서에서만 검색하는 함수\"\"\"\n",
        "    if source_filter:\n",
        "        # 특정 출처로 필터링 - source 필드가 keyword 타입이 아니므로 match 사용\n",
        "        search_body = {\n",
        "            \"size\": top_k,\n",
        "            \"query\": {\n",
        "                \"bool\": {\n",
        "                    \"must\": [\n",
        "                        {\"match\": {\"content\": {\"query\": query, \"operator\": \"or\"}}},\n",
        "                        {\"match\": {\"source\": source_filter}}\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"_source\": [\"content\", \"chunk_id\", \"source\"]\n",
        "        }\n",
        "    else:\n",
        "        # 전체 검색\n",
        "        search_body = {\n",
        "            \"size\": top_k,\n",
        "            \"query\": {\n",
        "                \"match\": {\n",
        "                    \"content\": {\n",
        "                        \"query\": query,\n",
        "                        \"operator\": \"or\"\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"_source\": [\"content\", \"chunk_id\", \"source\"]\n",
        "        }\n",
        "    \n",
        "    response = es.search(index=index_name, body=search_body)\n",
        "    results = []\n",
        "    \n",
        "    for hit in response['hits']['hits']:\n",
        "        source_info = hit['_source'].get('source', '서울든든급식')\n",
        "        results.append({\n",
        "            'chunk_id': hit['_source']['chunk_id'],\n",
        "            'score': hit['_score'],\n",
        "            'content': hit['_source']['content'],\n",
        "            'source': source_info\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# 필터 검색 테스트\n",
        "test_query = \"대표\"\n",
        "\n",
        "print(f\"🔍 검색어: '{test_query}'\\n\")\n",
        "\n",
        "# 1. 전체 검색\n",
        "print(\"1️⃣ 전체 문서에서 검색:\")\n",
        "all_results = search_by_source(test_query, nori_index, source_filter=None, top_k=5)\n",
        "for i, result in enumerate(all_results, 1):\n",
        "    source_emoji = \"🍽️\" if result['source'] == \"서울든든급식\" else \"🚀\"\n",
        "    print(f\"   [{i}] {source_emoji} {result['source']} - 점수: {result['score']:.3f}\")\n",
        "    print(f\"       {result['content'][:70]}...\")\n",
        "\n",
        "# 2. 서울든든급식에서만 검색\n",
        "print(\"\\n2️⃣ 서울든든급식 문서에서만 검색:\")\n",
        "seoul_results = search_by_source(test_query, nori_index, source_filter=\"서울든든급식\", top_k=3)\n",
        "if seoul_results:\n",
        "    for i, result in enumerate(seoul_results, 1):\n",
        "        print(f\"   [{i}] 🍽️ 점수: {result['score']:.3f}\")\n",
        "        print(f\"       {result['content'][:70]}...\")\n",
        "else:\n",
        "    print(\"   검색 결과 없음\")\n",
        "\n",
        "# 3. AX브릿지위원회에서만 검색  \n",
        "print(\"\\n3️⃣ AX브릿지위원회 문서에서만 검색:\")\n",
        "ax_results = search_by_source(test_query, nori_index, source_filter=\"AX브릿지위원회\", top_k=3)\n",
        "if ax_results:\n",
        "    for i, result in enumerate(ax_results, 1):\n",
        "        print(f\"   [{i}] 🚀 점수: {result['score']:.3f}\")\n",
        "        print(f\"       {result['content'][:70]}...\")\n",
        "else:\n",
        "    print(\"   검색 결과 없음\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🎉 통합 검색 시스템 완성!\n",
        "\n",
        "## 📋 구현된 기능들:\n",
        "\n",
        "### 1. 📄 다중 문서 지원\n",
        "- **서울든든급식** 문서 (기존)\n",
        "- **AX브릿지위원회** 문서 (신규 추가)\n",
        "- 총 **40+개 chunk**로 확장\n",
        "\n",
        "### 2. 🔍 3가지 검색 방식\n",
        "- **Standard 분석기**: 기본 영문 중심\n",
        "- **Nori 분석기**: 한글 형태소 분석 (최적화)\n",
        "- **N-gram 분석기**: 2-3글자 단위 분할\n",
        "\n",
        "### 3. 🎯 고급 검색 기능\n",
        "- **통합 검색**: 모든 문서에서 동시 검색\n",
        "- **필터 검색**: 특정 문서에서만 검색\n",
        "- **출처 표시**: 검색 결과에 문서 출처 표시\n",
        "- **검색 통계**: 문서별 검색 결과 분포 분석\n",
        "\n",
        "### 4. 📊 성능 분석 도구\n",
        "- **토크나이저 비교**: 각 분석기의 토큰 분할 결과\n",
        "- **점수 기반 랭킹**: BM25 점수로 관련도 순 정렬\n",
        "- **시각적 구분**: 이모지로 문서 출처 구분\n",
        "\n",
        "## 🚀 사용 방법:\n",
        "1. 노트북 셀을 순서대로 실행\n",
        "2. 원하는 검색어로 테스트\n",
        "3. 필터 기능으로 특정 문서에서만 검색 가능\n",
        "\n",
        "## 🎯 결론:\n",
        "**Nori 분석기를 사용한 한글 BM25 검색 시스템이 성공적으로 구축되었습니다!**\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🏆 한글 BM25 최적화 결론\n",
        "\n",
        "## ✅ Nori 분석기 (가장 추천):\n",
        "- 한국어 형태소 분석으로 의미 단위 분리\n",
        "- 복합어 자동 분해 (\"든든급식\" → \"든든\" + \"급식\")\n",
        "- 불용어 제거로 검색 정확도 향상\n",
        "- 가장 정확한 한글 검색 결과\n",
        "\n",
        "## ✅ N-gram 분석기 (대안):\n",
        "- 부분 매칭에 강함\n",
        "- 설치 없이 즉시 사용 가능\n",
        "- 노이즈가 있지만 기본 대비 큰 향상\n",
        "\n",
        "## ❌ Standard 분석기:\n",
        "- 영문 중심 설계\n",
        "- 한글 복합어 처리 한계\n",
        "- 부분 검색 불가\n",
        "\n",
        "## 🎯 권장사항:\n",
        "**한글 문서에서 BM25를 사용할 때는 반드시 Nori 분석기를 사용하세요!**\n",
        "검색 정확도와 사용자 경험이 크게 향상됩니다.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "elastic-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
